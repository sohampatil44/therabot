name: Therabot Deployment

on:
  workflow_dispatch:
    inputs:
      stage:
        description: "Deployment stage (dev/prod)"
        required: true
        default: "dev"

jobs:
  deploy:
    name: Deploy to therabot-${{ github.event.inputs.stage }}
    runs-on: ubuntu-latest
    
    env:
      AWS_REGION: us-east-1
      STAGE: ${{ github.event.inputs.stage || 'dev' }}

    steps:
      - name: Checkout code
        uses: actions/checkout@v3
        
      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v2
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}  

      # Install Terraform
      - name: Install Terraform
        uses: hashicorp/setup-terraform@v2
        with:
          terraform_version: 1.5.7
    
      # Terraform Reconfigure Backend (only first run)
      - name: Terraform Reconfigure Backend (Force Copy)
        if: always()
        run: |
          terraform init -reconfigure -force-copy \
            -backend-config="bucket=therabot-terraform-state" \
            -backend-config="key=therabot/terraform.tfstate" \
            -backend-config="region=us-east-1" \
            -backend-config="dynamodb_table=therabot-terraform-lock" \
            -backend-config="encrypt=true"
        
      # Terraform Init
      - name: Terraform Init
        run: |
          terraform init \
            -backend-config="bucket=therabot-terraform-state" \
            -backend-config="key=therabot/terraform.tfstate" \
            -backend-config="region=us-east-1" \
            -backend-config="dynamodb_table=therabot-terraform-lock" \
            -backend-config="encrypt=true"

      # Terraform Plan
      - name: Terraform Plan
        id: terraform_plan
        run: |
          terraform plan -lock=false -out=tfplan \
            -var "stage=${{ github.event.inputs.stage || 'dev' }}" \
            -var-file="terraform.tfvars" \
            -var "github_token=${{ secrets.REPO_ACCESS_TOKEN }}"

      # Terraform Apply
      - name: Terraform Apply
        id: terraform_apply
        run: |
          terraform apply -lock=false tfplan 2>&1 | tee terraform-apply.log

      # Upload Terraform logs
      - name: Upload Terraform Logs
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: terraform-logs
          path: terraform-apply.log

      # Get ALB DNS
      - name: GET ALB DNS
        run: |
          alb_dns=$(terraform output -raw alb_dns_name 2>/dev/null | tr -d '\r\n')
          if [ -z "$alb_dns" ]; then
            echo "::error::ALB DNS is empty"
            exit 1
          fi
          echo "ALB_DNS=$alb_dns" >> $GITHUB_ENV

      # Get EC2 public IP
      - name: Get EC2 public IP
        id: ec2_ip
        run: |
          ip=$(aws ec2 describe-instances \
            --filters "Name=tag:Name,Values=k3s-master-asg" "Name=instance-state-name,Values=running" \
            --query "Reservations[*].Instances[*].PublicIpAddress" \
            --output text | tr -d '\r\n' | awk 'NF && $1!="None" {print $1; exit}')
          
          if [[ $ip =~ ^[0-9]+\.[0-9]+\.[0-9]+\.[0-9]+$ ]]; then
            echo "EC2_PUBLIC_IP=$ip" >> $GITHUB_ENV
            echo "ec2_public_ip=$ip" >> $GITHUB_OUTPUT
            echo "Successfully found therabot-asg instance IP: $ip"
          else
            echo "::error::Could not find valid therabot-asg instance IP address: '$ip'"
            exit 1
          fi

      - name: Show App URL
        run: echo "App live on http://${{ env.ALB_DNS }}"

      # Install kubectl
      - name: Install kubectl
        uses: azure/setup-kubectl@v3
        with:
          version: 'latest'

      # Setup SSH key for master node
      - name: Setup SSH to Master Node
        run: |
          mkdir -p ~/.ssh
          echo "${{ secrets.EC2_KEYPAIR_PRIVATE_KEY }}" > ~/.ssh/network-keypair.pem
          chmod 600 ~/.ssh/network-keypair.pem

      # COMPLETE VERSION WITH INTEGRATED KUBECONFIG FIX
      - name: Wait for k3s cluster initialization
        run: |
          echo "üîÑ Waiting for k3s cluster (max 5 minutes)..."
          
          # First, debug our permissions
          echo "üîç Testing AWS/SSM permissions:"
          aws sts get-caller-identity || echo "No AWS identity"
          aws ssm describe-parameters --max-items 1 >/dev/null 2>&1 && echo "‚úÖ SSM accessible" || echo "‚ùå SSM not accessible"
          
          # Show what parameters exist
          echo "üìã Existing SSM parameters:"
          aws ssm describe-parameters --filters "Key=Name,Values=/therabot/,/k3s/" --query "Parameters[*].[Name,LastModifiedDate]" --output table || echo "No parameters found"
          
          timeout=300  # 5 minutes only
          elapsed=0
          interval=15  # Check every 15 seconds
          
          while [ $elapsed -lt $timeout ]; do
            echo "‚è≥ Checking... (${elapsed}s/${timeout}s)"
            
            # Try to get the parameter (no --with-decryption since we're using String now)
            kubeconfig_content=$(aws ssm get-parameter \
              --name "/therabot/kubeconfig" \
              --query "Parameter.Value" \
              --output text \
              --region us-east-1 2>/dev/null || echo "")
            
            if [ -n "$kubeconfig_content" ] && [ "$kubeconfig_content" != "None" ]; then
              echo "üìÑ Kubeconfig found in SSM (${#kubeconfig_content} chars)"
              
              # Save it
              echo "$kubeconfig_content" > kubeconfig
              chmod 600 kubeconfig
              
              # INTEGRATED FIX: Check and fix kubeconfig server endpoint if needed
              echo "üîß Checking and fixing kubeconfig server endpoint..."
              
              # Show what we got from SSM
              echo "üìÑ Original kubeconfig server:"
              grep "server:" kubeconfig || echo "No server line found"
              
              # If it still points to localhost/127.0.0.1, fix it
              current_server=$(grep "server:" kubeconfig | awk '{print $2}' || echo "")
              echo "Current server: $current_server"
              
              if [[ "$current_server" == *"127.0.0.1"* ]] || [[ "$current_server" == *"localhost"* ]]; then
                echo "‚ö†Ô∏è Kubeconfig still points to localhost, fixing with EC2 public IP..."
                
                # Replace with the EC2 public IP we found earlier
                if [[ -n "${{ env.EC2_PUBLIC_IP }}" ]]; then
                  echo "üîß Updating kubeconfig to use public IP: ${{ env.EC2_PUBLIC_IP }}"
                  sed -i "s|https://127.0.0.1:6443|https://${{ env.EC2_PUBLIC_IP }}:6443|g" kubeconfig
                  sed -i "s|https://localhost:6443|https://${{ env.EC2_PUBLIC_IP }}:6443|g" kubeconfig
                  
                  echo "‚úÖ Updated kubeconfig server:"
                  grep "server:" kubeconfig
                else
                  echo "‚ùå No EC2 public IP available to fix kubeconfig"
                  exit 1
                fi
              else
                echo "‚úÖ Kubeconfig server endpoint looks correct"
              fi
              
              # Test the connection with more debugging
              export KUBECONFIG=./kubeconfig
              echo "üîç Testing connection with verbose output..."
              if kubectl get nodes --v=6 --request-timeout=30s >/dev/null 2>&1; then
                echo "‚úÖ k3s cluster is ready!"
                kubectl get nodes
                break
              else
                echo "‚ùå Connection test failed. Debug info:"
                echo "Server endpoint: $(grep 'server:' kubeconfig)"
                echo "Testing port connectivity:"
                server_ip=$(grep 'server:' kubeconfig | sed 's|.*https://||' | sed 's|:6443.*||')
                timeout 10 nc -zv "$server_ip" 6443 || echo "Port 6443 not reachable"
                
                # Show more debug info
                echo "üîç Server endpoint being used: $server_ip:6443"
                echo "üîç EC2 Public IP from env: ${{ env.EC2_PUBLIC_IP }}"
              fi
            else
              echo "‚è≥ Kubeconfig not found in SSM yet..."
              
              # Show debug info every minute
              if [ $((elapsed % 60)) -eq 0 ] && [ $elapsed -gt 0 ]; then
                echo "üîç Debug info:"
                echo "EC2 instances:"
                aws ec2 describe-instances \
                  --filters "Name=tag:Name,Values=k3s-master-asg" "Name=instance-state-name,Values=running" \
                  --query "Reservations[*].Instances[*].[InstanceId,State.Name,LaunchTime]" \
                  --output table || echo "Failed to get instances"
              fi
            fi
            
            sleep $interval
            elapsed=$((elapsed + interval))
          done
          
          if [ $elapsed -ge $timeout ]; then
            echo "‚ùå TIMEOUT after ${timeout}s"
            
            # Final debug info
            echo "üîç Final debug:"
            echo "All SSM parameters:"
            aws ssm describe-parameters --query "Parameters[*].[Name,LastModifiedDate]" --output table || echo "Failed to list parameters"
            
            echo "EC2 instance details:"
            aws ec2 describe-instances \
              --filters "Name=tag:Name,Values=k3s-master-asg" \
              --query "Reservations[*].Instances[*].[InstanceId,State.Name,PublicIpAddress,LaunchTime]" \
              --output table || echo "Failed to get instance details"
            
            exit 1
          fi

      # Verify k3s cluster (redundant check but good to have)
      - name: Verify k3s cluster connectivity
        run: |
          export KUBECONFIG=./kubeconfig
          echo "üîç Final cluster verification:"
          kubectl cluster-info --request-timeout=30s
          kubectl get nodes -o wide

      # Create namespace if missing
      - name: Create namespace if not exists
        run: |
          export KUBECONFIG=./kubeconfig
          if ! kubectl get namespace development >/dev/null 2>&1; then
            kubectl create namespace development
            echo "üìÅ Created development namespace"
          else
            echo "üìÅ Development namespace already exists"
          fi

      # Validate Kubernetes manifests
      - name: Validate Kubernetes manifests
        run: |
          export KUBECONFIG=./kubeconfig
          if [ ! -d "k8s" ] || [ -z "$(ls -A k8s 2>/dev/null)" ]; then
            echo "::error::k8s directory empty"
            exit 1
          fi
          kubectl apply -f k8s/ --dry-run=client --namespace=development

      # Deploy manifests
      - name: Deploy manifests to k3s cluster
        run: |
          export KUBECONFIG=./kubeconfig
          kubectl apply -f k8s/ --namespace=development
          
          # Wait for deployments
          for deploy in $(kubectl get deployments -n development -o name 2>/dev/null || echo ""); do
            if [ -n "$deploy" ]; then
              echo "‚è≥ Waiting for $deploy..."
              kubectl rollout status $deploy -n development --timeout=300s
            fi
          done

      - name: Show Kubernetes App URL
        run: echo "üöÄ App live on http://${{ steps.ec2_ip.outputs.ec2_public_ip }}:30080"

      # Deployment verification
      - name: Verify Deployment
        run: |
          export KUBECONFIG=./kubeconfig
          kubectl get all -n development

      # Cleanup on failure
      - name: Cleanup on failure
        if: failure() || cancelled()
        run: |
          echo "üßπ Workflow failed or cancelled. Cleaning up..."
          if [ -f kubeconfig ]; then
            export KUBECONFIG=./kubeconfig
            kubectl delete namespace development --grace-period=30 --timeout=120s || true
          fi
          terraform destroy -auto-approve \
            -var "stage=${{ github.event.inputs.stage || 'dev' }}" \
            -var-file="terraform.tfvars" \
            -var "github_token=${{ secrets.REPO_ACCESS_TOKEN }}" || true

      # Remove kubeconfig
      - name: Remove kubeconfig
        if: always()
        run: rm -f ./kubeconfig